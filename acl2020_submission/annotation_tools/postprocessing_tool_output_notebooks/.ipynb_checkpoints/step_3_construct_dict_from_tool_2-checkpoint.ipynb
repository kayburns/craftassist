{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import argparse\n",
    "import json\n",
    "from collections import defaultdict, Counter\n",
    "import re\n",
    "from operator import itemgetter\n",
    "MAX_WORDS=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_repeat_dict(d):\n",
    "    if d[\"loop\"] == \"ntimes\":\n",
    "        repeat_dict = {\"repeat_key\": \"FOR\"}\n",
    "        processed_d = process_dict(with_prefix(d, \"loop.ntimes.\"))\n",
    "        if 'repeat_for' in processed_d:\n",
    "            repeat_dict[\"repeat_count\"] = processed_d[\"repeat_for\"]\n",
    "        if 'repeat_dir' in processed_d:\n",
    "            repeat_dict['repeat_dir'] = processed_d['repeat_dir']\n",
    "        return repeat_dict\n",
    "    if d[\"loop\"] == \"repeat_all\":\n",
    "        repeat_dict = {\"repeat_key\": \"ALL\"}\n",
    "        processed_d = process_dict(with_prefix(d, \"loop.repeat_all.\"))\n",
    "        if 'repeat_dir' in processed_d:\n",
    "            repeat_dict['repeat_dir'] = processed_d['repeat_dir']\n",
    "        return repeat_dict\n",
    "    if d[\"loop\"] == \"forever\":\n",
    "        return {\"stop_condition\": {\"condition_type\": \"NEVER\"}}\n",
    "    if d['loop'] == 'repeat_until':\n",
    "        stripped_d = with_prefix(d, 'loop.repeat_until.')\n",
    "        processed_d = process_dict(stripped_d)\n",
    "        if 'adjacent_to_block_type' in processed_d:\n",
    "            return {\"stop_condition\" : {\n",
    "                        \"condition_type\" : 'ADJACENT_TO_BLOCK_TYPE',\n",
    "                        'block_type': processed_d['adjacent_to_block_type']}\n",
    "                   }\n",
    "    raise NotImplementedError(\"Bad repeat dict option: {}\".format(d[\"loop\"]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_get_memory_dict(d):\n",
    "    filters_val = d['filters']\n",
    "    out_dict = {'filters': {}}\n",
    "    parent_dict = {}\n",
    "    if filters_val.startswith('type.'):\n",
    "        parts = remove_prefix(filters_val, 'type.').split('.')\n",
    "        type_val = parts[0]\n",
    "        if type_val in ['ACTION', 'AGENT']:\n",
    "            out_dict['filters']['temporal'] = 'CURRENT'\n",
    "            tag_val = parts[1]\n",
    "            out_dict['answer_type'] = 'TAG'\n",
    "            out_dict['tag_name'] = parts[1] # the name of tag is here\n",
    "            if type_val == 'ACTION':\n",
    "                x = with_prefix(d, 'filters.'+filters_val+'.')\n",
    "                out_dict['filters'].update(x)\n",
    "        elif type_val in ['REFERENCE_OBJECT']:\n",
    "            d.pop('filters')\n",
    "            ref_obj_dict = remove_key_prefixes(d, ['filters.type.'])\n",
    "            ref_dict = process_dict(ref_obj_dict)\n",
    "            if 'answer_type' in ref_dict['reference_object']:\n",
    "                out_dict['answer_type'] = ref_dict['reference_object']['answer_type']\n",
    "                ref_dict['reference_object'].pop('answer_type')\n",
    "            if 'tag_name' in ref_dict['reference_object']:\n",
    "                out_dict['tag_name'] = ref_dict['reference_object']['tag_name']\n",
    "                ref_dict['reference_object'].pop('tag_name')    \n",
    "            out_dict['filters'].update(ref_dict)\n",
    "            \n",
    "        out_dict['filters']['type'] = type_val\n",
    "        \n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_prefix(text, prefix):\n",
    "    if text.startswith(prefix):\n",
    "        return text[len(prefix):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_get_memory(d):\n",
    "    out_d = {'dialogue_type': 'GET_MEMORY'}\n",
    "    child_d = process_get_memory_dict(with_prefix(d, \"action_type.ANSWER.\"))\n",
    "    out_d.update(child_d)\n",
    "    return out_d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert s to snake case\n",
    "def snake_case(s):\n",
    "    return re.sub(\"([a-z])([A-Z])\", \"\\\\1_\\\\2\", s).lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''this function splits the key that starts with a given prefix and only for values that are not None\n",
    "and makes the key be the thing after prefix\n",
    "'''\n",
    "def with_prefix(d, prefix):\n",
    "    new_d = {}\n",
    "    for k, v in d.items():\n",
    "        if k.startswith(prefix) and v not in (\"\", None, \"None\"):\n",
    "            index = k.find(prefix)+ len(prefix)\n",
    "            new_key = k[index:]\n",
    "            new_d[new_key] = v\n",
    "    return new_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' this function removes certain prefixes from keys and renames the key to be: key with text following \n",
    "the prefix in the dict'''\n",
    "def remove_key_prefixes(d, ps):\n",
    "    \n",
    "    for p in ps:\n",
    "        d = d.copy()\n",
    "        rm_keys = []\n",
    "        add_items = []\n",
    "        # print(p, d)\n",
    "        for k, v in d.items():\n",
    "            if k.startswith(p):\n",
    "                rm_keys.append(k)\n",
    "                add_items.append((k[len(p) :], v))\n",
    "        for k in rm_keys:\n",
    "            del d[k]\n",
    "        for k, v in add_items:\n",
    "            d[k] = v\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_spans_due_to_empty_words(action_dict, words):\n",
    "    \"\"\"Return modified (action_dict, words)\"\"\"\n",
    "\n",
    "    def reduce_span_vals_gte(d, i):\n",
    "        for k, v in d.items():\n",
    "            if type(v) == dict:\n",
    "                reduce_span_vals_gte(v, i)\n",
    "                continue\n",
    "            try:\n",
    "                a, b = v\n",
    "                if a >= i:\n",
    "                    a -= 1\n",
    "                if b >= i:\n",
    "                    b -= 1\n",
    "                d[k] = [[a, b]]\n",
    "            except ValueError:\n",
    "                pass\n",
    "            except TypeError:\n",
    "                pass\n",
    "\n",
    "    # remove trailing empty strings\n",
    "    while words[-1] == \"\":\n",
    "        del words[-1]\n",
    "\n",
    "    # fix span\n",
    "    i = 0\n",
    "    while i < len(words):\n",
    "        if words[i] == \"\":\n",
    "            reduce_span_vals_gte(action_dict, i)\n",
    "            del words[i]\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "    return action_dict, words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dict(d):\n",
    "    r = {}\n",
    "\n",
    "    d = remove_key_prefixes(d, [\"name_check.\",\n",
    "                                \"rel_yaw.\",\n",
    "                                \"angle.check.\",\n",
    "                                \"rel_pitch.\",\n",
    "                                \"check.\",\n",
    "                                \"yaw_check.\",\n",
    "                                \"pitch_check.\",\n",
    "                                \"location_check.\",\n",
    "                                \"size_check.\", \n",
    "                                'colour_check.', \n",
    "                                'block_type_check.', \n",
    "                                'height_check.', \n",
    "                                'length_check.',\n",
    "                                'width_check.',\n",
    "                                'tag_check.',\n",
    "                                'thickness_check.',\n",
    "                                'coordinates_check.yes.',\n",
    "                                'coref_resolve_check.yes.',\n",
    "                                'name_check.coref_resolve_check.yes.',\n",
    "                                'name_check.coref_resolve_check.no.',\n",
    "                                'coref_resolve_check.no.',\n",
    "                                'depth_check.',\n",
    "                               'reward.'])\n",
    "    if \"location\" in d:\n",
    "        # fix location type\n",
    "        r[\"location\"] = {\"location_type\": d[\"location\"]}\n",
    "        \n",
    "        # fix relative direction\n",
    "        reference_location_keys = [\"location.REFERENCE_OBJECT.relative_direction\",\n",
    "                                   \"location.SPEAKER_LOOK_REL.relative_direction\",\n",
    "                                   \"location.SPEAKER_POS_REL.relative_direction\",\n",
    "                                   \"location.AGENT_POS_REL.relative_direction\"\n",
    "                                   ]\n",
    "        if any(x in reference_location_keys for x in d.keys()):\n",
    "            for k, v in d.items():\n",
    "                if k in reference_location_keys:\n",
    "                    r[\"location\"][\"relative_direction\"] = d.get(k)\n",
    "                    d[k] = None        \n",
    "        # fix steps\n",
    "        if (k.startswith(\"location.REFERENCE_OBJECT.steps\") for k, v in d.items()):\n",
    "            new_d = {}\n",
    "            for k, v in d.items():\n",
    "                if k.startswith(\"location.REFERENCE_OBJECT.steps\"):\n",
    "                    parts = k.split(\".\")\n",
    "                    new_l = [parts[0]]\n",
    "                    new_l.extend(parts[2:])\n",
    "                    new_key = \".\".join(new_l)\n",
    "                    new_d[new_key] = v\n",
    "                else:\n",
    "                    new_d[k ] = v\n",
    "\n",
    "            d = new_d\n",
    "        \n",
    "        if r['location']['location_type'] in ['AGENT_POS_REL', 'SPEAKER_POS_REL', 'SPEAKER_LOOK_REL']:\n",
    "            r['location']['location_type'] = ''.join(r['location']['location_type'][0:-4]) \n",
    "        \n",
    "        if r['location']['location_type'] == 'CONTAINS_COREFERENCE':\n",
    "            del r['location']['location_type']\n",
    "            r['location']['contains_coreference'] = 'yes'\n",
    "            r[\"location\"].update(process_dict(with_prefix(d, \"location.\")))\n",
    "        elif r['location']['location_type'] == 'coordinates_check':\n",
    "            r['location']['location_type'] = 'COORDINATES'\n",
    "            r[\"location\"].update(process_dict(with_prefix(d, \"location.\")))\n",
    "            #r['location']['coordinates'] = d[\"location.coordinates_check.yes.coordinates\"]\n",
    "        elif r['location']['location_type'] == 'coref_resolve_check':\n",
    "            del r['location']['location_type']\n",
    "            r[\"location\"].update(process_dict(with_prefix(d, \"location.\")))\n",
    "        elif r[\"location\"][\"location_type\"] == \"REFERENCE_OBJECT\":            \n",
    "            r[\"location\"][\"location_type\"] = \"REFERENCE_OBJECT\"\n",
    "            # update steps in old data\n",
    "            \n",
    "            if (\"relative_direction\" in r[\"location\"]):\n",
    "                x = process_dict(with_prefix(d, \"location.REFERENCE_OBJECT.relative_direction.{}.\".format(r[\"location\"][\"relative_direction\"])))\n",
    "                r[\"location\"].update(x)\n",
    "                dirn = r[\"location\"][\"relative_direction\"]\n",
    "                for k, v in d.items():\n",
    "                    if k.startswith('location.REFERENCE_OBJECT.relative_direction.{}.reference_object.has_name.'.format(dirn)):\n",
    "                        d[k] = None\n",
    "                    if k.startswith('location.REFERENCE_OBJECT.relative_direction.{}.reference_object.location.'.format(dirn)):\n",
    "                        d[k] = None\n",
    "                    if k.startswith(\"location.REFERENCE_OBJECT.relative_direction.{}.reference_object.contains_coreference\".format(dirn)):\n",
    "                        d[k] = None\n",
    "                    if k.startswith('location.REFERENCE_OBJECT.relative_direction.{}.reference_object_1.has_name.'.format(r[\"location\"][\"relative_direction\"])):\n",
    "                        d[k] = None\n",
    "                    if k.startswith(\"location.REFERENCE_OBJECT.relative_direction.{}.reference_object_1.contains_coreference\".format(r[\"location\"][\"relative_direction\"])):\n",
    "                        d[k] = None\n",
    "                    if k.startswith('location.REFERENCE_OBJECT.relative_direction.{}.reference_object_2.has_name.'.format(r[\"location\"][\"relative_direction\"])):\n",
    "                        d[k] = None\n",
    "                    if k.startswith(\"location.REFERENCE_OBJECT.relative_direction.{}.reference_object_2.contains_coreference\".format(r[\"location\"][\"relative_direction\"])):\n",
    "                        d[k] = None\n",
    "            else:\n",
    "                del r[\"location\"][\"location_type\"]\n",
    "            # no key for EXACT\n",
    "        if (\"relative_direction\" in r[\"location\"]) and (r[\"location\"][\"relative_direction\"] in (\"EXACT\", \"Other\")):\n",
    "            del r[\"location\"][\"relative_direction\"]\n",
    "            \n",
    "\n",
    "    \n",
    "    for k, v in d.items():\n",
    "        \n",
    "        if (\n",
    "            k == \"location\"\n",
    "            or k in ['COPY']\n",
    "            or (k == \"relative_direction\" and v in (\"EXACT\", \"NEAR\", \"Other\"))\n",
    "        ):\n",
    "            continue\n",
    "        # handle span\n",
    "        if re.match(\"[^.]+.span#[0-9]+\", k):\n",
    "            prefix, rest = k.split(\".\", 1)\n",
    "            idx = int(rest.split(\"#\")[-1])\n",
    "            if prefix in r:\n",
    "                r[prefix].append([idx, idx])\n",
    "                r[prefix] = sorted(r[prefix], key=itemgetter(0))\n",
    "            else:\n",
    "                r[prefix] = [[idx, idx]]\n",
    "        elif k == 'reference_object' and v == 'contains_coreference.yes':\n",
    "            r['reference_object'] = {'contains_coreference': 'yes'}\n",
    "\n",
    "        # handle nested dict\n",
    "        elif \".\" in k:\n",
    "            prefix, rest = k.split(\".\", 1)\n",
    "            prefix_snake = snake_case(prefix)\n",
    "            r[prefix_snake] = r.get(prefix_snake, {})\n",
    "            r[prefix_snake].update(process_dict(with_prefix(d, prefix + \".\")))\n",
    "\n",
    "        # handle const value\n",
    "        else:\n",
    "            r[k] = v\n",
    "        \n",
    "    return r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_put_memory(d):\n",
    "    return {}\n",
    "    \n",
    "\n",
    "def handle_components(d, child_name):\n",
    "    output = {}\n",
    "            \n",
    "    if child_name == 'tag_val':\n",
    "        output['upsert'] = {}\n",
    "        r = output['upsert']\n",
    "        if 'memory_data' in d:\n",
    "            r['memory_data'] = {}\n",
    "            mem_type = d['memory_data'].split(\".\")\n",
    "            r['memory_data'][mem_type[0]] = mem_type[1].upper()\n",
    "            if r['memory_data']['memory_type'] == 'REWARD':\n",
    "                filtered = with_prefix(d, \"memory_data.memory_type.reward.\")\n",
    "            else:\n",
    "                filtered = with_prefix(d, \"memory_data.memory_type.\")\n",
    "            r[\"memory_data\"].update(filtered)\n",
    "        \n",
    "    elif child_name == 'filters':\n",
    "        output['filters'] = {'reference_object': {}}\n",
    "        if any(k.startswith('reference_object') and v == 'contains_coreference.yes' for k, v in d.items()):\n",
    "            output['filters']['reference_object']['contains_coreference'] = 'yes'\n",
    "\n",
    "        child_d = process_dict(with_prefix(d, \"{}.\".format('reference_object')))\n",
    "        output['filters']['reference_object'].update(child_d)\n",
    "    elif child_name == 'location':\n",
    "        child_d = process_dict(d)\n",
    "        output.update(child_d)\n",
    "    elif child_name =='reference_object' and any(k.startswith('reference_object') and v == 'contains_coreference.yes' for k, v in d.items()):\n",
    "        output[child_name] = {'contains_coreference': 'yes'}\n",
    "        child_d = process_dict(with_prefix(d, \"{}.\".format(child_name)))\n",
    "        output[child_name].update(child_d)\n",
    "    else:\n",
    "        child_d = process_dict(with_prefix(d, \"{}.\".format(child_name)))\n",
    "        # remove an extra \"angle\" from yaw and picth spans\n",
    "        if child_d.get('relative_pitch', None):\n",
    "            if 'pitch_span' in child_d['relative_pitch']:\n",
    "                child_d['relative_pitch'].pop('angle')\n",
    "        elif child_d.get('relative_yaw', None):\n",
    "            if 'yaw_span' in child_d['relative_yaw']:\n",
    "                child_d['relative_yaw'].pop('angle')\n",
    "        output[child_name] = child_d\n",
    "\n",
    "    return output\n",
    "\n",
    "def process_result(full_d):\n",
    "    worker_id = full_d[\"WorkerId\"]\n",
    "    action_name = full_d['Input.intent']\n",
    "    child_name = full_d['Input.child']\n",
    "    d = with_prefix(full_d, \"Answer.root.\"+action_name+\".\") # replace with \"Answer.root.\"\n",
    "    action_dict = handle_components(d, child_name)\n",
    "   \n",
    "\n",
    "    # Fix empty words messing up spans\n",
    "    words = [full_d[\"Input.word{}\".format(x)] for x in range(MAX_WORDS)]\n",
    "    action_dict, words = fix_spans_due_to_empty_words(action_dict, words)\n",
    "\n",
    "    return worker_id, action_dict, words, child_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Read turk output, convert turk answers into a dictionary and\n",
    "compile all three answers per command and child into result_dict\n",
    "'''\n",
    "\n",
    "from pprint import pprint\n",
    "import json\n",
    "\n",
    "'''\n",
    "command: Input.command\n",
    "\n",
    "'''\n",
    "from pprint import pprint\n",
    "result_dict = {}\n",
    "\n",
    "# folder and file name of the output file of tool2 from Turk\n",
    "folder_name = '' # folder with tool 2 output data\n",
    "f_name = folder_name + 'out.csv'\n",
    "only_show_disagreements=True\n",
    "sentence_mapping = {}\n",
    "with open(f_name, \"r\") as f:\n",
    "    r = csv.DictReader(f)\n",
    "    for i, d in enumerate(r):\n",
    "        sentence = d['Input.command']\n",
    "        ''' the sentence has a span in it'''\n",
    "\n",
    "        worker_id, action_dict, words, child_name = process_result(d)\n",
    "        \n",
    "        if action_dict is None:\n",
    "            continue\n",
    "        command = \" \".join(words)\n",
    "        command = command + \"$$$\" + child_name\n",
    "        \n",
    "        sentence_mapping[command] = sentence\n",
    "        result = json.dumps(action_dict)\n",
    "\n",
    "        if command in result_dict:\n",
    "            if len(result_dict[command]) == 3:\n",
    "                continue\n",
    "            result_dict[command].append(result)\n",
    "        else:\n",
    "            result_dict[command] = [result]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "write result_dict to txt as:\n",
    "command \\t child_name \\t dict1 \\t dict2 \\t dict3\n",
    "'''\n",
    "import json\n",
    "# file name of file that contains the formatted txt\n",
    "f_name = folder_name + 'out.txt'\n",
    "\n",
    "with open(f_name, 'w') as outfile:\n",
    "    for k, v in result_dict.items():\n",
    "        cmd, child  = k.split(\"$$$\")\n",
    "        if len(v) != 3:\n",
    "            items = v[0] + \"\\t\" + v[0] + \"\\t\" + v[0]\n",
    "        else:\n",
    "            items=  \"\\t\".join(v)\n",
    "        outfile.write(cmd + \"\\t\" + child + \"\\t\" + items+\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_definite_articles(cmd, d):\n",
    "    words = cmd.split()\n",
    "    if type(d) == str:\n",
    "        #print(d)\n",
    "        d = ast.literal_eval(d)\n",
    "    new_d = {}\n",
    "    # print(d)\n",
    "    for k, v in d.items():\n",
    "        if type(v) == dict:\n",
    "            new_d[k] = {}\n",
    "            for k1, v1 in v.items():\n",
    "                if type(v1) == list:\n",
    "                    new_v = []\n",
    "                    for span in v1:\n",
    "                        # span[0] and span[1] are the same\n",
    "                        if words[span[0]] in ['the', 'a', 'an']:\n",
    "                            continue\n",
    "                        new_v.append(span)\n",
    "                    new_d[k][k1] = new_v  \n",
    "                elif type(v1) == dict:\n",
    "                    v_new = remove_definite_articles(cmd, v1)\n",
    "                    new_d[k][k1] = v_new\n",
    "                    \n",
    "                else:\n",
    "                    new_d[k][k1] = v1\n",
    "        # for internal nodes\n",
    "        else:\n",
    "            if type(v) == list:\n",
    "                new_v = []\n",
    "                for span in v:\n",
    "                    # span[0] and span[1] are the same\n",
    "                    if words[span[0]] in ['the', 'a', 'an']:\n",
    "                        continue\n",
    "                    new_v.append(span)\n",
    "                new_d[k] = new_v  \n",
    "            elif type(v) == dict:\n",
    "                v_new = remove_definite_articles(cmd, v)\n",
    "                new_d[k] = v_new\n",
    "\n",
    "            else:\n",
    "                new_d[k] = v\n",
    "                    \n",
    "    return new_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# construct counter of each dict per command, from txt\n",
    "result_counts = defaultdict(Counter)\n",
    "import ast\n",
    "f_name = folder_name + 'out.txt'\n",
    "with open(f_name) as in_data:\n",
    "    for line in in_data.readlines():\n",
    "        line = line.strip()\n",
    "        cmd, child, r1, r2, r3 = line.split(\"\\t\")\n",
    "        for r in [r1, r2, r3]:\n",
    "            r_new = remove_definite_articles(cmd, r)\n",
    "            result_counts[cmd+\"$$$\"+child][json.dumps(r_new)] += 1\n",
    "print(len(result_counts.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# compute agreements and disagreements\n",
    "no_agreement = 0\n",
    "num_agreements = 2\n",
    "agreement = 0\n",
    "only_show_disagreements = False\n",
    "disagreement = defaultdict(Counter)\n",
    "all_agreements_dict = {}\n",
    "for command, counts in sorted(result_counts.items()):\n",
    "    if not any(v >= num_agreements for v in counts.values()):\n",
    "        if only_show_disagreements:\n",
    "            print(command)\n",
    "        disagreement[command] = counts\n",
    "        no_agreement += 1\n",
    "        continue\n",
    "    elif only_show_disagreements:\n",
    "        continue\n",
    "\n",
    "    #print(command)\n",
    "\n",
    "    for result, count in counts.items():\n",
    "        if count >= num_agreements:\n",
    "            all_agreements_dict[command] = result\n",
    "            agreement += 1\n",
    "            #print(result)\n",
    "\n",
    "    #print()\n",
    "print(agreement)\n",
    "print(no_agreement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out agreements to a file\n",
    "## format is : command child dict\n",
    "agreements_file = 'agreements.txt'\n",
    "with open(folder_name + agreements_file, 'w') as outfile:\n",
    "    for k, v in all_agreements_dict.items():\n",
    "        cmd, child = k.split('$$$')\n",
    "        outfile.write(cmd + \"\\t\" + child + \"\\t\" + v + \"\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write disagreements to a file\n",
    "disagreements_file = 'disagreements.txt'\n",
    "with open(folder_name + disagreements_file, 'w') as outfile:\n",
    "    for k, v in disagreement.items():\n",
    "        cmd, child = k.split('$$$')\n",
    "        outfile.write(cmd+\"\\t\"+child+\"\\n\")\n",
    "        for item in v:\n",
    "            outfile.write(item+\"\\n\")\n",
    "        outfile.write(\"\\n\")\n",
    "        outfile.write(\"\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "from operator import itemgetter\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import ast\n",
    "from operator import itemgetter\n",
    "\n",
    "def resolve_spans(words, dicts):\n",
    "    result = {}\n",
    "    for d, val in dicts.items():\n",
    "        new_d = {}\n",
    "        d = ast.literal_eval(d)\n",
    "        for k1, v1 in d.items():\n",
    "            inner = {}\n",
    "            for k, v in v1.items():\n",
    "                #print(v)\n",
    "                if type(v) == list:\n",
    "                    new_v = []\n",
    "                    for item in v:\n",
    "                        if item[0] == item[1]:\n",
    "                            new_v.append(words[item[0]])\n",
    "#                         else:\n",
    "#                             for item in v:\n",
    "#                                 new_v.append(words[item])\n",
    "                    inner[k] = new_v\n",
    "                elif k =='repeat':\n",
    "                    \n",
    "                    if 'stop_condition' in v:\n",
    "                        new_v = {}\n",
    "                        new_v['stop_condition'] = {}\n",
    "                        x = {}\n",
    "                        x['condition_type'] = v['stop_condition']['condition_type']\n",
    "\n",
    "                        new_vals = []\n",
    "                        if v['stop_condition']['block_type'][0] ==v['stop_condition']['block_type'][1]:\n",
    "                            new_vals.append(words[v['stop_condition']['block_type'][0]])\n",
    "                        else:\n",
    "                            for item in v['stop_condition']['block_type']:\n",
    "                                new_vals.append(words[item])\n",
    "                        x['block_type'] = new_vals\n",
    "                        new_v['stop_condition'] = x\n",
    "                        inner['repeat'] = new_v \n",
    "                else:\n",
    "                    inner[k] = v\n",
    "            new_d[k1] = inner\n",
    "        result[str(new_d)] = val\n",
    "    return result\n",
    "\n",
    "for command, counts in disagreement.items():\n",
    "    words = command.split()\n",
    "    parts = words[-1].split(\"$$$\")\n",
    "    print(sentence_mapping[command])\n",
    "    words[-1] = parts[0]\n",
    "    child_name = parts[1]\n",
    "    command = \" \".join(words)\n",
    "    #print(words, counts)\n",
    "    c = resolve_spans(words, counts)\n",
    "    print(command, child_name)\n",
    "    #print(counts)\n",
    "    # print(\"*\"*30)\n",
    "    for k, v in c.items():\n",
    "        pprint(ast.literal_eval(k))\n",
    "        print(\"-\"*10)\n",
    "    #print(c)\n",
    "    print(\"*\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine agreements and resolved disagreements\n",
    "with open(folder_name+'all_agreements.txt', 'w') as f, \\\n",
    "     open(folder_name + agreements_file) as f1, \\\n",
    "     open(folder_name + disagreements_file) as f2:\n",
    "    for line in f1.readlines():\n",
    "        line = line.strip()\n",
    "        f.write(line+ \"\\n\")\n",
    "    for line in f2.readlines():\n",
    "        line = line.strip()\n",
    "        f.write(line+ \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
