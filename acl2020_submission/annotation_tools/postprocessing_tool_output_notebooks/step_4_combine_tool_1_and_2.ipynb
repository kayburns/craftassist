{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output agreements file of tool 1\n",
    "folder_name_1 = '' # folder containing data from tool1 \n",
    "tool_1_out_file = folder_name_1 + 'all_agreements.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output of tool 2\n",
    "folder_name_2 = '' # # folder containing data from tool2\n",
    "tool_2_out_file = folder_name_2 + 'all_agreements.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine outputs\n",
    "# check if all keys of t1 annotated yes -> put directly\n",
    "# if no , check child in t2 and combine\n",
    "# construct mape of tool 1\n",
    "tool1_map = {}\n",
    "with open(tool_1_out_file) as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.strip()\n",
    "        cmd, a_d = line.split(\"\\t\")\n",
    "        tool1_map[cmd]= a_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct map of tool 2\n",
    "tool2_map = {}\n",
    "import os.path\n",
    "from os import path\n",
    "\n",
    "if path.isfile(tool_2_out_file):\n",
    "    with open(tool_2_out_file) as f2:\n",
    "        for line in f2.readlines():\n",
    "            line = line.strip()\n",
    "            cmd, child, child_dict = line.split(\"\\t\")\n",
    "            if cmd in tool2_map and child in tool2_map[cmd]:\n",
    "                print(\"BUGGG\")\n",
    "            if cmd not in tool2_map:\n",
    "                tool2_map[cmd] = {}\n",
    "            tool2_map[cmd][child] = child_dict        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "def all_yes(a_dict):\n",
    "    if type(a_dict) == str:\n",
    "        a_dict = ast.literal_eval(a_dict)\n",
    "    for k, val in a_dict.items():\n",
    "        if type(val) == list and val[0] == \"no\":\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def clean_dict_1(a_dict):\n",
    "    if type(a_dict) == str:\n",
    "        a_dict = ast.literal_eval(a_dict)\n",
    "    new_d = {}\n",
    "    for k, val in a_dict.items():\n",
    "        if type(val) == list:\n",
    "            if val[0] in [\"yes\", \"no\"]:\n",
    "                new_d[k] = val[1]                \n",
    "        elif type(val) == dict:\n",
    "            new_d[k] = a_dict(val[1])\n",
    "        else:\n",
    "            new_d[k] = val\n",
    "    \n",
    "    if 'dance_type_span' in new_d:\n",
    "        new_d['dance_type'] = {}\n",
    "        new_d['dance_type']['dance_type_span'] = new_d['dance_type_span']\n",
    "        new_d.pop('dance_type_span')\n",
    "    return new_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# post_process spans and \"contains_coreference\" : \"no\"\n",
    "def merge_indices(indices):\n",
    "    a, b = indices[0]\n",
    "    for i in range(1, len(indices)):\n",
    "        a = min(a, indices[i][0])\n",
    "        b = max(b, indices[i][1])\n",
    "    return [a, b]\n",
    "\n",
    "def fix_put_mem(d):\n",
    "    \n",
    "    if type(d) == str:\n",
    "        d = ast.literal_eval(d)\n",
    "    new_d = copy.deepcopy(d)\n",
    "    del new_d['action_type']\n",
    "    if 'has_tag' in new_d and 'upsert' in new_d:\n",
    "        new_d['upsert']['memory_data']['has_tag'] = new_d['has_tag']\n",
    "        del new_d['has_tag']\n",
    "\n",
    "    return new_d\n",
    "\n",
    "def fix_spans(d):\n",
    "    new_d = {}\n",
    "    if type(d) == str:\n",
    "        d = ast.literal_eval(d)\n",
    "    for k, v in d.items():\n",
    "        if k == \"contains_coreference\" and v == \"no\":\n",
    "            continue\n",
    "        if type(v) == list:\n",
    "            if k == \"tag_val\":\n",
    "                new_d[\"has_tag\"] = [0, merge_indices(v)] \n",
    "            else:\n",
    "                new_d[k] = [0, merge_indices(v)] \n",
    "            continue\n",
    "        elif type(v) == dict:\n",
    "            new_d[k] = fix_spans(v)\n",
    "            continue\n",
    "        else:\n",
    "            new_d[k] = v\n",
    "    return new_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "come here\n",
      "{'action_type': 'MOVE',\n",
      " 'dialogue_type': 'HUMAN_GIVE_COMMAND',\n",
      " 'location': {'contains_coreference': 'yes'}}\n",
      "****************************************\n"
     ]
    }
   ],
   "source": [
    "# combine and write output to a file\n",
    "i  =0\n",
    "import copy\n",
    "# what these action will look like in the map\n",
    "import json\n",
    "dance_type_map = {\n",
    "    'point': 'point',\n",
    "    'look': 'look_turn',\n",
    "    'turn' : 'body_turn'\n",
    "}\n",
    "\n",
    "from pprint import pprint\n",
    "# update dict of tool1 with tool 2\n",
    "folder_name_combined = '' # folder where the combine dcit will be written\n",
    "file_name_combined = folder_name_combined + 'all_combined.txt' # filename of combined file\n",
    "\n",
    "with open(folder_name_combined + 'all_combined.txt', 'w') as f:\n",
    "    for cmd, a_dict in tool1_map.items():\n",
    "        # remove the ['yes', val] etc\n",
    "        clean_dict = clean_dict_1(a_dict)\n",
    "        if all_yes(a_dict):\n",
    "            f.write(cmd + \"\\t\" + json.dumps(clean_dict) + \"\\n\")\n",
    "            continue\n",
    "        if clean_dict['action_type'] == 'noop':\n",
    "            f.write(cmd + \"\\t\" + json.dumps(clean_dict) + \"\\n\")\n",
    "            continue\n",
    "        if clean_dict['action_type'] == 'otheraction':\n",
    "            f.write(cmd + \"\\t\" + str(a_dict) + \"\\n\")\n",
    "            continue\n",
    "\n",
    "        if tool2_map:\n",
    "            child_dict_all = tool2_map[cmd]\n",
    "            # update action dict with all children except for reference object\n",
    "            for k, v in child_dict_all.items():\n",
    "                if k not in clean_dict:\n",
    "                    print(\"BUGGGG\")\n",
    "                if type(v) == str:\n",
    "                    v = ast.literal_eval(v)\n",
    "                if not v:\n",
    "                    continue\n",
    "                if k == \"tag_val\":\n",
    "                    clean_dict.update(v)\n",
    "                elif k == \"facing\":\n",
    "                    action_type = clean_dict['action_type']\n",
    "                    # set to dance\n",
    "                    clean_dict['action_type'] = 'DANCE'\n",
    "                    clean_dict['dance_type'] = {dance_type_map[action_type]: v['facing']}\n",
    "                    clean_dict.pop('facing')\n",
    "                else:\n",
    "                    clean_dict[k] = v[k]\n",
    "\n",
    "        actual_dict = copy.deepcopy((clean_dict))\n",
    "\n",
    "        action_type = actual_dict['action_type']\n",
    "\n",
    "#         valid_dict = {}\n",
    "#         valid_dict['dialogue_type'] = actual_dict['dialogue_type']\n",
    "#        del actual_dict['dialogue_type']\n",
    "        actual_dict['action_type'] = actual_dict['action_type'].upper()\n",
    "        act_dict = fix_spans(actual_dict)\n",
    "        #valid_dict.update(act_dict)\n",
    "        #valid_dict['action_sequence'] = [act_dict]\n",
    "        print(cmd)\n",
    "        pprint(act_dict)\n",
    "        print(\"*\"*40)\n",
    "        f.write(cmd + \"\\t\" + json.dumps(act_dict) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dialogue_type': 'HUMAN_GIVE_COMMAND', 'action_sequence': [{'action_type': 'MOVE', 'location': {'contains_coreference': 'yes'}}]}\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# for composites\n",
    "# now skip composite_action and separate otheraction from combined dicts\n",
    "mypath = '' # path to combined dict folder\n",
    "import ast\n",
    "import json\n",
    "\n",
    "f = []\n",
    "all_cnt  = 0\n",
    "cmp  = 0\n",
    "other = 0\n",
    "valid = 0\n",
    "all_comp = set()\n",
    "with open(mypath + \"all_combined.txt\") as f_read, open(mypath + 'all_combined_final.txt', 'w') as f:\n",
    "    for line in f_read.readlines():\n",
    "        line = line.strip()\n",
    "\n",
    "        text, d = line.split(\"\\t\")\n",
    "        actual_dict = ast.literal_eval(d.strip())\n",
    "        action_type = actual_dict['action_type']\n",
    "        if action_type == 'composite_action':\n",
    "            print(line)\n",
    "            cmp += 1\n",
    "            all_comp.add(text.strip())\n",
    "            continue\n",
    "        else:\n",
    "            valid += 1\n",
    "            valid_dict = {}\n",
    "            valid_dict['dialogue_type'] = actual_dict['dialogue_type']\n",
    "            del actual_dict['dialogue_type']\n",
    "            actual_dict['action_type'] = actual_dict['action_type'].upper()\n",
    "            valid_dict['action_sequence'] = [actual_dict]\n",
    "            print(valid_dict)\n",
    "            f.write(text.strip() + \"\\t\" + json.dumps(valid_dict) + \"\\n\")\n",
    "print(cmp)\n",
    "print(len(all_comp))\n",
    "print(other)\n",
    "print(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "9\n",
      "259\n",
      "1893\n"
     ]
    }
   ],
   "source": [
    "# now skip composite_action and separate otheraction from combined dicts\n",
    "mypath = '' # path to folder containing all files\n",
    "from os import walk\n",
    "import ast\n",
    "import json\n",
    "\n",
    "f = []\n",
    "all_cnt  = 0\n",
    "cmp  = 0\n",
    "other = 0\n",
    "valid = 0\n",
    "all_comp = set()\n",
    "with open(mypath + \"all_final_annotations.txt\", 'w') as f_final, open(mypath + \"all_other_actions.txt\", 'w') as f_other:\n",
    "    for (dirpath, dirnames, filenames) in walk(mypath):\n",
    "        if filenames:\n",
    "            for file_name in filenames:\n",
    "                if not (file_name.startswith('.') or file_name in ['all_final_annotations.txt', 'all_other_actions.txt']):\n",
    "                    fn  = dirpath + file_name\n",
    "                    with open(fn) as f:\n",
    "                        for line in f.readlines():\n",
    "                            line = line.strip()\n",
    "\n",
    "                            text, d = line.split(\"\\t\")\n",
    "                            actual_dict = ast.literal_eval(d.strip())\n",
    "                            action_type = actual_dict['action_type']\n",
    "                            if action_type == 'composite_action':\n",
    "                                cmp += 1\n",
    "                                all_comp.add(text.strip())\n",
    "                                continue\n",
    "                            elif action_type[1] == 'otheraction':\n",
    "                                other += 1\n",
    "                                f_other.write(line + \"\\n\")\n",
    "                            else:\n",
    "                                valid += 1\n",
    "                                valid_dict = {}\n",
    "                                valid_dict['dialogue_type'] = actual_dict['dialogue_type']\n",
    "                                del actual_dict['dialogue_type']\n",
    "                                actual_dict['action_type'] = actual_dict['action_type'].upper()\n",
    "                                valid_dict['action_sequence'] = [actual_dict]\n",
    "                                f_final.write(text.strip() + \"\\t\" + json.dumps(valid_dict) + \"\\n\")\n",
    "print(cmp)\n",
    "print(len(all_comp))\n",
    "print(other)\n",
    "print(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# more postprocessing\n",
    "        \n",
    "i = 0\n",
    "input_file = '' # combined final file from previous step\n",
    "output_file = '' # final file\n",
    "with open(input_file) as f, open(output_file, 'w') as f_w:\n",
    "    for line in f.readlines():\n",
    "        i+= 1\n",
    "        line = line.strip()\n",
    "        text, d = line.split(\"\\t\")\n",
    "        \n",
    "        d = ast.literal_eval(d)\n",
    "        action_dict = fix_spans(d['action_sequence'][0])\n",
    "        if action_dict['action_type'] == 'TAG':\n",
    "            updated_dict = fix_put_mem(action_dict)\n",
    "            new_d = {}\n",
    "            new_d['dialogue_type'] = d['dialogue_type']\n",
    "            new_d.update(updated_dict)\n",
    "        elif action_dict['action_type'] == 'ANSWER':\n",
    "            #print(d)\n",
    "            new_d = {}\n",
    "            new_d['dialogue_type'] = 'GET_MEMORY'\n",
    "        else:\n",
    "            if action_dict['action_type'] == 'COPY':\n",
    "                action_dict['action_type'] = 'BUILD'\n",
    "            d['action_sequence'] = [action_dict]\n",
    "            new_d = d\n",
    "        f_w.write(text+  \"\\t\" + json.dumps(new_d) + \"\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
