\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{lauria2001training,bos2007spoken,tellex2011understanding,matuszek2013learning,thomason2019improving}
\citation{campagna2017almond,kollar2018alexa,campagna2019genie}
\citation{dong2016language,jia2016data,zhong2017seq2sql}
\citation{gray2019craftassist}
\citation{kollar2013toward,thomason2015learning,wang2016learning,wang2017naturalizing}
\citation{yi2018neural}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:AS}{{1}{2}{The basic structure of the \textsc {action\_sequence} branch of the assistant's grammar. The gold octagon is an internal node whose children are ordered, blue rectangles are regular internal nodes, and green rectangles are categorical leaf nodes. Not all combinations of children of \textsc {action} are possible, see the full list of possible productions (and the productions for \textsc {put\_memory} and \textsc {get\_memory}) in the Appendix \ref {sec:action_tree}.\relax }{figure.caption.1}{}}
\newlabel{sec:grammar}{{2}{2}{The Assistant Grammar}{section.2}{}}
\newlabel{fig:NOT_AS}{{2}{2}{The basic structure of internal nodes in the assistant's grammar. Blue rectangles are internal nodes, green rectangles are categorical leaf nodes, and red ovals are span nodes. \relax }{figure.caption.2}{}}
\newlabel{fig:tool}{{3}{3}{A representation of the annotation process using the web-based annotation tool described in Section \ref {sec:annotation}. The colors of the boxes correspond to annotation tasks. The highlighting on the text in the header of the later tasks is provided by a previous annotator. We show more detailed screenshots of how the tool works in Appendix \ref {sec:anntn}\relax }{figure.caption.3}{}}
\newlabel{fig:action_freqs}{{4}{4}{Frequency of each action type in the different data collection schemes described in Section~\ref {sec:collected_data}.  \relax }{figure.caption.4}{}}
\newlabel{sec:data}{{3}{4}{The CAIP Dataset}{section.3}{}}
\newlabel{sec:collected_data}{{3.1}{4}{Collected Data}{subsection.3.1}{}}
\newlabel{sec:prompts}{{3.1.1}{4}{Image and Text Prompts}{subsubsection.3.1.1}{}}
\newlabel{fig:quant_sent_len}{{5}{4}{Histograms showing distribution over number of nodes in a logical form (top) and utterance length in words (bottom) for each data type. Prompts averages 6.74 nodes per logical form, 7.32 words per utterance, and interactive averages 4.89, 3.42 respectively\relax }{figure.caption.5}{}}
\newlabel{sec:human_bot}{{3.1.2}{4}{Interactive Gameplay}{subsubsection.3.1.2}{}}
\newlabel{sec:annotation}{{3.1.3}{4}{Annotation Tool}{subsubsection.3.1.3}{}}
\citation{yih2016value}
\citation{yih2016value}
\citation{price1990evaluation,tang2001using,cai2013large,wang2015building,zhong2017seq2sql}
\citation{price1990evaluation,tang2001using,cai2013large}
\citation{wang2015building}
\citation{zhong2017seq2sql}
\citation{lauria2001training,bos2007spoken,tellex2011understanding,matuszek2013learning,thomason2019improving}
\citation{Boye2006RobustSL}
\citation{wang2017naturalizing}
\citation{dong2016language}
\citation{devlin2018bert}
\citation{jia2016data,zhong2017seq2sql,wang2018transfer,hwang2019comprehensive}
\citation{hwang2019comprehensive}
\citation{artzi2013weakly,liang2016neural,guu2017language}
\citation{riedel2016programming,neelakantan2016learning}
\newlabel{sec:dataset_statistics}{{3.2}{5}{Dataset Statistics}{subsection.3.2}{}}
\newlabel{sec:quant_analysis}{{3.2.3}{5}{Quantitative analysis}{subsubsection.3.2.3}{}}
\citation{johnson2016malmo}
\citation{shu2017hierarchical,udagawa2016fighting,alaniz2018deep,oh2016control,tessler2017deep}
\citation{guss2019minerlCompetition,guss2019minerl}
\citation{oh2017zero}
\citation{kitaev2017misty,yi2018neural}
\citation{allison2018players}
\citation{dong2016language}
\citation{ChoMGBBSB14}
\newlabel{tab:ling_1}{{1}{6}{Choice of words across different data sources for the same logical form (per column).\relax }{table.caption.6}{}}
\newlabel{sec:modeling}{{5}{6}{Baseline Models}{section.5}{}}
\citation{jia2016data,wang2018transfer}
\citation{jia2016data}
\citation{song2019mass}
\citation{sanh2019distilbert}
\newlabel{eq:int_pred}{{3}{7}{Prediction Heads:}{equation.5.3}{}}
\newlabel{eq:cat_pred}{{4}{7}{Prediction Heads:}{equation.5.4}{}}
\newlabel{eq:span_pred}{{5}{7}{Prediction Heads:}{equation.5.5}{}}
\citation{BojanowskiGJM17}
\citation{yao2019interactive}
\newlabel{tab:main-results}{{2}{8}{Average accuracy over a test set of 650 Prompts + 350 Interactive.\relax }{table.caption.13}{}}
\newlabel{sec:experiments}{{6}{8}{Experiments}{section.6}{}}
\newlabel{tab:beam-search}{{3}{8}{Recall at N for the Seq2Seq model beam search.\relax }{table.caption.14}{}}
\newlabel{fig:mistakes}{{6}{8}{We show nodes in the grammar which are most often wrongly predicted, with false positive (+) and false negative counts (-).\relax }{figure.caption.16}{}}
\bibdata{refs}
\bibcite{alaniz2018deep}{{1}{2018}{{Alaniz}}{{}}}
\bibcite{allison2018players}{{2}{2018}{{Allison et~al.}}{{Allison, Luger, and Hofmann}}}
\bibcite{artzi2013weakly}{{3}{2013}{{Artzi and Zettlemoyer}}{{}}}
\bibcite{BojanowskiGJM17}{{4}{2017}{{Bojanowski et~al.}}{{Bojanowski, Grave, Joulin, and Mikolov}}}
\bibcite{bos2007spoken}{{5}{2007}{{Bos and Oka}}{{}}}
\bibcite{Boye2006RobustSL}{{6}{2006}{{Boye et~al.}}{{Boye, Gustafson, and Wir{\'e}n}}}
\bibcite{cai2013large}{{7}{2013}{{Cai and Yates}}{{}}}
\bibcite{campagna2017almond}{{8}{2017}{{Campagna et~al.}}{{Campagna, Ramesh, Xu, Fischer, and Lam}}}
\bibcite{campagna2019genie}{{9}{2019}{{Campagna et~al.}}{{Campagna, Xu, Moradshahi, Socher, and Lam}}}
\bibcite{ChoMGBBSB14}{{10}{2014}{{Cho et~al.}}{{Cho, van Merrienboer, G{\"{u}}l{\c {c}}ehre, Bahdanau, Bougares, Schwenk, and Bengio}}}
\bibcite{devlin2018bert}{{11}{2018}{{Devlin et~al.}}{{Devlin, Chang, Lee, and Toutanova}}}
\bibcite{dong2016language}{{12}{2016}{{Dong and Lapata}}{{}}}
\bibcite{gray2019craftassist}{{13}{2019}{{Gray et~al.}}{{Gray, Srinet, Jernite, Yu, Chen, Guo, Goyal, Zitnick, and Szlam}}}
\bibcite{guss2019minerlCompetition}{{14}{2019{a}}{{Guss et~al.}}{{Guss, Codel, Hofmann, Houghton, Kuno, Milani, Mohanty, Liebana, Salakhutdinov, Topin et~al.}}}
\bibcite{guss2019minerl}{{15}{2019{b}}{{Guss et~al.}}{{Guss, Houghton, Topin, Wang, Codel, Veloso, and Salakhutdinov}}}
\bibcite{guu2017language}{{16}{2017}{{Guu et~al.}}{{Guu, Pasupat, Liu, and Liang}}}
\bibcite{hwang2019comprehensive}{{17}{2019}{{Hwang et~al.}}{{Hwang, Yim, Park, and Seo}}}
\bibcite{jia2016data}{{18}{2016}{{Jia and Liang}}{{}}}
\bibcite{johnson2016malmo}{{19}{2016}{{Johnson et~al.}}{{Johnson, Hofmann, Hutton, and Bignell}}}
\bibcite{kitaev2017misty}{{20}{2017}{{Kitaev and Klein}}{{}}}
\bibcite{kollar2018alexa}{{21}{2018}{{Kollar et~al.}}{{Kollar, Berry, Stuart, Owczarzak, Chung, Mathias, Kayser, Snow, and Matsoukas}}}
\bibcite{kollar2013toward}{{22}{2013}{{Kollar et~al.}}{{Kollar, Krishnamurthy, and Strimel}}}
\bibcite{lauria2001training}{{23}{2001}{{Lauria et~al.}}{{Lauria, Bugmann, Kyriacou, Bos, and Klein}}}
\bibcite{liang2016neural}{{24}{2016}{{Liang et~al.}}{{Liang, Berant, Le, Forbus, and Lao}}}
\bibcite{matuszek2013learning}{{25}{2013}{{Matuszek et~al.}}{{Matuszek, Herbst, Zettlemoyer, and Fox}}}
\bibcite{neelakantan2016learning}{{26}{2016}{{Neelakantan et~al.}}{{Neelakantan, Le, Abadi, McCallum, and Amodei}}}
\bibcite{oh2016control}{{27}{2016}{{Oh et~al.}}{{Oh, Chockalingam, Singh, and Lee}}}
\bibcite{oh2017zero}{{28}{2017}{{Oh et~al.}}{{Oh, Singh, Lee, and Kohli}}}
\bibcite{price1990evaluation}{{29}{1990}{{Price}}{{}}}
\bibcite{riedel2016programming}{{30}{2016}{{Riedel et~al.}}{{Riedel, Bosnjak, and Rockt{\"a}schel}}}
\bibcite{sanh2019distilbert}{{31}{2019}{{Sanh et~al.}}{{Sanh, Debut, Chaumond, and Wolf}}}
\bibcite{shu2017hierarchical}{{32}{2017}{{Shu et~al.}}{{Shu, Xiong, and Socher}}}
\bibcite{song2019mass}{{33}{2019}{{Song et~al.}}{{Song, Tan, Qin, Lu, and Liu}}}
\bibcite{tang2001using}{{34}{2001}{{Tang and Mooney}}{{}}}
\bibcite{tellex2011understanding}{{35}{2011}{{Tellex et~al.}}{{Tellex, Kollar, Dickerson, Walter, Banerjee, Teller, and Roy}}}
\bibcite{tessler2017deep}{{36}{2017}{{Tessler et~al.}}{{Tessler, Givony, Zahavy, Mankowitz, and Mannor}}}
\bibcite{thomason2019improving}{{37}{2019}{{Thomason et~al.}}{{Thomason, Padmakumar, Sinapov, Walker, Jiang, Yedidsion, Hart, Stone, and Mooney}}}
\bibcite{thomason2015learning}{{38}{2015}{{Thomason et~al.}}{{Thomason, Zhang, Mooney, and Stone}}}
\bibcite{udagawa2016fighting}{{39}{2016}{{Udagawa et~al.}}{{Udagawa, Narasimhan, and Lee}}}
\bibcite{wang2017naturalizing}{{40}{2017}{{Wang et~al.}}{{Wang, Ginn, Liang, and Manning}}}
\bibcite{wang2016learning}{{41}{2016}{{Wang et~al.}}{{Wang, Liang, and Manning}}}
\bibcite{wang2018transfer}{{42}{2018}{{Wang et~al.}}{{Wang, Tian, Xiong, Wang, and Ku}}}
\bibcite{wang2015building}{{43}{2015}{{Wang et~al.}}{{Wang, Berant, and Liang}}}
\bibcite{yao2019interactive}{{44}{2019}{{Yao et~al.}}{{Yao, Su, Sun, and Yih}}}
\bibcite{yi2018neural}{{45}{2018}{{Yi et~al.}}{{Yi, Wu, Gan, Torralba, Kohli, and Tenenbaum}}}
\bibcite{yih2016value}{{46}{2016}{{Yih et~al.}}{{Yih, Richardson, Meek, Chang, and Suh}}}
\bibcite{zhong2017seq2sql}{{47}{2017}{{Zhong et~al.}}{{Zhong, Xiong, and Socher}}}
\bibstyle{acl_natbib}
\newlabel{sec:supplemental}{{7}{13}{Conclusion}{section*.18}{}}
\newlabel{sec:data_cleanup}{{A}{13}{Basic Data Cleanup}{appendix.A}{}}
\newlabel{sec:instructions}{{B}{13}{Crowd-sourced task and tools instructions}{appendix.B}{}}
\newlabel{sec:freegen_instructions}{{B.1}{13}{Image and Text Prompts}{subsection.B.1}{}}
\newlabel{fig:freegen}{{7}{13}{The task instructions shown to crowd-sourced workers for the Image and text prompts task\relax }{figure.caption.19}{}}
\newlabel{fig:appen}{{8}{13}{The task instructions shown to crowd-sourced workers for the interactive game play\relax }{figure.caption.20}{}}
\newlabel{sec:appen}{{B.2}{13}{Interactive Gameplay}{subsection.B.2}{}}
\newlabel{sec:anntn}{{B.3}{13}{Annotation tool}{subsection.B.3}{}}
\newlabel{sec:tool_a}{{B.3.1}{13}{Tool a}{subsubsection.B.3.1}{}}
\newlabel{fig:annotation_task1}{{9}{14}{The task instructions shown to crowd-sourced workers for the annotation Tool a\relax }{figure.caption.21}{}}
\newlabel{sec:tool_b}{{B.3.2}{14}{Tool b}{subsubsection.B.3.2}{}}
\newlabel{sec:composite}{{B.4}{14}{Tool for composite commands}{subsection.B.4}{}}
\newlabel{fig:annotation_step1}{{10}{14}{The step by step screenshot of annotations process for the command: ``build three sets of bookshelves in front of me .'' in Tool a\relax }{figure.caption.22}{}}
\newlabel{fig:annotation_task2}{{11}{15}{The task instructions shown to crowd-sourced workers for the annotation Tool b\relax }{figure.caption.23}{}}
\newlabel{fig:move_location}{{12}{15}{The step by step screenshot of annotating properties of highlighted words for``location'' in a ``Move'' action.\relax }{figure.caption.24}{}}
\newlabel{fig:destroy_ref}{{13}{15}{The step by step screenshot of annotating properties of highlighted words for``reference\_object'' in a ``Destroy'' action.\relax }{figure.caption.25}{}}
\newlabel{fig:comp}{{14}{15}{The task instructions shown to crowd-sourced workers for splitting composite commands\relax }{figure.caption.26}{}}
\newlabel{sec:action_tree}{{C}{16}{Action Tree structure}{appendix.C}{}}
\newlabel{fig:ref_obj}{{15}{16}{Logical form of a reference\_object child\relax }{figure.caption.27}{}}
\newlabel{fig:location}{{16}{16}{Logical form of a location child\relax }{figure.caption.28}{}}
\newlabel{fig:action_tree_ex}{{17}{16}{An example logical form. The spans are indexed as : [sentence\_number, [starting\_word\_index, ending\_word\_index]]. sentence\_number is 0 for the most recent sentence spoken in a dialogue and is 0 in our dataset since we support one-turn dialogues as of now.\relax }{figure.caption.29}{}}
\newlabel{fig:build_dict}{{18}{17}{Details of logical form for Build\relax }{figure.caption.30}{}}
\newlabel{fig:copy_dict}{{19}{17}{Details of logical form for Copy\relax }{figure.caption.31}{}}
\newlabel{fig:spawn_dict}{{20}{17}{Details of logical form for Spawn action\relax }{figure.caption.32}{}}
\newlabel{fig:fill_dict}{{21}{17}{Details of logical form for Fill\relax }{figure.caption.33}{}}
\newlabel{fig:destroy_dict}{{22}{18}{Details of logical form Destroy\relax }{figure.caption.34}{}}
\newlabel{fig:move_dict}{{23}{18}{Details of logical form for Move action\relax }{figure.caption.35}{}}
\newlabel{fig:dig_dict}{{24}{18}{Details of logical form for Dig action\relax }{figure.caption.36}{}}
\newlabel{fig:dance_dict}{{25}{18}{Details of logical form for Dance action\relax }{figure.caption.37}{}}
\newlabel{fig:freebuild_dict}{{26}{18}{Details of logical form for Freebuild action\relax }{figure.caption.38}{}}
\newlabel{fig:undo_dict}{{27}{18}{Details of logical form for Undo action\relax }{figure.caption.39}{}}
\newlabel{fig:stop_dict}{{28}{18}{Details of logical form for Stop action\relax }{figure.caption.40}{}}
\newlabel{fig:resume_dict}{{29}{18}{Details of logical form for Resume action\relax }{figure.caption.41}{}}
\newlabel{fig:answer_dict}{{30}{18}{Details of logical form for Get Memory Dialogue\relax }{figure.caption.42}{}}
\newlabel{fig:tag_dict}{{31}{19}{Details of logical form for Put Memory Dialogue\relax }{figure.caption.43}{}}
\newlabel{fig:noop_dict}{{32}{19}{Details of logical form for Noop Dialogue\relax }{figure.caption.44}{}}
\newlabel{sec:dataset_examples}{{D}{20}{Crowd-sourced task and tools instructions}{appendix.D}{}}
